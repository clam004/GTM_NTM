{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version 1.3.0\n",
      "torch.cuda.is_available() True\n"
     ]
    }
   ],
   "source": [
    "import math, copy, sys, logging, json, time, random, os\n",
    "\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from scripts.Memory import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print('torch.version',torch.__version__)\n",
    "print('torch.cuda.is_available()',torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GENERATIVE TEMPORAL MODELS WITH MEMORY](https://arxiv.org/pdf/1702.04649.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = RecallTaskMNISTParams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder\n",
    "\n",
    "A neural network maps an input tensor to the mean and log variance of the latent variable z. z is then sampled in a differentiable manner from the distribution parameterized by the mean and log variance. \n",
    "\n",
    "## Relation between prior and posterior of the Latent variable \n",
    "\n",
    "if you look at the forward method of the VAE and the variables passed into it in the combined model\n",
    "\n",
    "def forward(self, psi_t, x_t, batch_size):\n",
    "\n",
    "self.state.latentstate.state, X_mean, elbo = self.vae(self.state.readstate.r, X, batch_size)\n",
    "\n",
    "the context psi_t is the same as the read vector self.state.readstate.r\n",
    "\n",
    "There are two functions that are being learned by the VAE \n",
    "\n",
    "<img src=\"saved/images/priorposterior.png\">\n",
    "\n",
    "The prior is a diagonal Gaussian that depends on the memory context through the prior map f_z\n",
    "\n",
    "The posterior is a diagonal Gaussian that depends on the observation x_t and the memory context Ψ_t−1 through a posterior map f_q\n",
    "\n",
    "f_z and f_q are both neural networks that predict the latent variable z, the ELBO simultaneously pushes f_z to encode a latent variable z that can generate x_t as well as a f_q that encodes a latent variable z that encodes the same information that f_z does\n",
    "\n",
    "## sampling z\n",
    "\n",
    "Since the neural network outputs positive or negative valued vectors, we predict the log variance instead of the variance, since the log variance is negative for variances less than 1 and positive for variances greater than 1. Then we convert the log variance to standard deviation  using `(0.5 * z_logvar).exp()` \n",
    "\n",
    "$$ e^{0.5 \\cdot \\log \\sigma^2} = \\sigma $$\n",
    "\n",
    "The KL-divergence between two gaussians is outlined in this article https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians basically you need each distribution's mean and variance \n",
    "\n",
    "$$\n",
    "KL(p, q) = \\int p(x) \\log \\frac{p(x)}{q(x)} dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "= - \\int p(x) \\log q(x) dx + \\int p(x) \\log p(x) dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\frac{1}{2} \\log (2 \\pi \\sigma_2^2) + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2 \\sigma_2^2} - \\frac{1}{2} (1 + \\log 2 \\pi \\sigma_1^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\log \\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2 \\sigma_2^2} - \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\log \\sigma_2 - \\log \\sigma_1 + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2 \\sigma_2^2} - \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{\\log \\sigma_2^2 - \\log \\sigma_1^2}{2} + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{2 \\sigma_2^2} - \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{2} ( \\log \\sigma_2^2 - \\log \\sigma_1^2 + \\frac{\\sigma_1^2 + (\\mu_1 - \\mu_2)^2}{\\sigma_2^2} - 1) \n",
    "$$\n",
    "\n",
    "\n",
    "The coded version of the function above is below\n",
    "\n",
    "`kld_element = `\n",
    "\n",
    "`logvar_2 - logvar_1 + (logvar_1.exp() + (mean_1-mean_2).pow(2))/(logvar_2.exp()+1e-8) - 1`\n",
    "\n",
    "`return 0.5 * torch.sum(kld_element, dim = 1)`\n",
    "\n",
    "For the Reconstruction Loss we use negative log likelihood of Bernoulli \n",
    "random variable x, parameteried by p. In the VAE example, p is the output of the decoder [0,1], and x is the input {0,1}.\n",
    "\n",
    "The probability of x = 1 in bernoulli is theta, sometimes p, but i used theta s to not confuse this with marginal probability p(x)\n",
    "\n",
    "$$ p(x) = theta^{x}(1-theta)^{(1-x) $$\n",
    "\n",
    "Likelihood of a series of x random variables where x is {0 or 1}, and x is sampled n times is\n",
    "\n",
    "$$\n",
    "L(p) = \\prod_{i=1}^n p^{x_i}(1-p)^{(1-x_i)}\n",
    "$$\n",
    "\n",
    "The log-likelihood of a series of x random variables where x is {0 or 1}, and x is sampled n times is\n",
    "\n",
    "$$\n",
    "\\log [L(p)] = \\log{p}\\sum_{i=1}^n x_i + \\log{(1-p)}\\sum_{i=1}^n (1-x_i)\n",
    "$$\n",
    "\n",
    "The coded version of the function above is below, with a negative sign for negative log-likelihood (nll) \n",
    "\n",
    "`-torch.sum(x*torch.log(p+1e-8)+(1-x)*torch.log(1-p+1e-8),dim=1)`\n",
    "\n",
    "You might be used to seeing this formulas variables reversed,\n",
    "note that if x = y and p = x,this is the same as Binary Cross Entropy.\n",
    "\n",
    "ELBO (evidence lower bound  also called variational lower bound) is the objective function for a variational baysian method called inference optimization duality whereby you infer\n",
    "the value of a random variable given the value of another random variable by finding parameter values that minimize some objective function\n",
    "\n",
    "http://users.umiacs.umd.edu/~xyang35/files/understanding-variational-lower.pdf explains why ELBO is a lower bound of the log probability of observations log(p(x)).\n",
    "\n",
    "p(x) = marginal likelihood aka marginal probability of x \n",
    "\n",
    "$$ELBO = \\log p(x) - KL[ q(z) || p(z|x)] $$\n",
    "\n",
    "in the forward pass of the variational autoencoder\n",
    "\n",
    "`kld = self._kld_gauss(z_mean, z_logvar, z_mean_prior, z_logvar_prior)`\n",
    "`nll = self._nll_bernoulli(_x_t_mean, x_t)`\n",
    "`elbo_t = - nll - kld`\n",
    "\n",
    "a double negative is used in the ELBO which is confusing, nll = -loglikelihood, plugging this back into \n",
    "\n",
    "`elbo_t = - nll - kld` \n",
    "\n",
    "we get \n",
    "\n",
    "`elbo_t = loglikelihood - KLdivergence` \n",
    "\n",
    "to maximize the marginal probability, we can instead maximize its variational lower bound (ELBO) or minimize the negative mean ELBO\n",
    "\n",
    "in the training loop\n",
    "\n",
    "`mean_neg_elbo = -elbo.mean()` \n",
    "`mean_neg_elbo.backward()`\n",
    "\n",
    "the result is that we minimize the KL divergence while also minimizing the reconstruction loss aka maximizine the loglikelihood, log(p(x)), when p(x) is the bernoulli marginal likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalModelBase(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, z_dim, psi_dim):\n",
    "        super(VariationalModelBase, self).__init__()\n",
    "\n",
    "        self.x_dim = x_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.psi_dim = psi_dim\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        self.to(self.device)\n",
    "\n",
    "        self.init_nn_layers()\n",
    "\n",
    "    def init_nn_layers(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, psi_t, x_t, batch_size):\n",
    "\n",
    "        # compute Q(Z|X) given context and x_t\n",
    "        z_enc = self.inf(torch.cat([psi_t, x_t], dim=1))\n",
    "        z_mean = self.inf_mean(z_enc)\n",
    "        z_logvar = self.inf_logvar(z_enc)\n",
    "\n",
    "        # compute prior over z_t given context\n",
    "        z_enc_prior = self.prior(psi_t)\n",
    "        z_mean_prior = self.prior_mean(z_enc_prior)\n",
    "        z_logvar_prior = self.prior_logvar(z_enc_prior)\n",
    "\n",
    "        # get a sample of z_t\n",
    "        z_sample = self.sample_gaussian(z_mean, (0.5 * z_logvar).exp())\n",
    "\n",
    "        # get distribution over x_t given z_t and the context\n",
    "        _x_t_enc = self.gen(torch.cat([psi_t, z_sample], dim=1))\n",
    "        _x_t_mean = self.gen_mean(_x_t_enc)\n",
    "\n",
    "        # compute kld, log-likelihood of x_t and sub-elbo\n",
    "        kld = self._kld_gauss(z_mean, z_logvar, z_mean_prior, z_logvar_prior)\n",
    "        nll =  self._nll_bernoulli(_x_t_mean, x_t)\n",
    "        elbo_t = - nll - kld\n",
    "\n",
    "        return z_sample, _x_t_mean, elbo_t\n",
    "\n",
    "    def reset_parameters(self, stdv=1e-1):\n",
    "        for weight in self.parameters():\n",
    "            weight.data.normal_(0, stdv)\n",
    "\n",
    "\n",
    "    def sample_gaussian(self, mean, std):\n",
    "        normalsample = torch.randn(mean.size(), device = self.device)\n",
    "        return normalsample * std + mean  # scale the vector based on std and add mean\n",
    "\n",
    "\n",
    "    def sample_x_mean(self, psi):\n",
    "        # compute prior over z_t given context\n",
    "        z_enc_prior = self.prior(psi)\n",
    "        z_mean_prior = self.prior_mean(z_enc_prior)\n",
    "        z_logvar_prior = self.prior_logvar(z_enc_prior)\n",
    "        z_sample = self.sample_gaussian(z_mean_prior, (0.5 * z_logvar_prior).exp())\n",
    "        x_enc = self.gen(torch.cat([psi, z_sample], dim=1))\n",
    "        x_gen_mean = self.gen_mean(x_enc)\n",
    "        return z_sample, x_gen_mean\n",
    "\n",
    "\n",
    "    def _kld_gauss(self, mean_1, logvar_1, mean_2, logvar_2):\n",
    "        \"\"\"Using std to compute KLD\"\"\"\n",
    "\n",
    "        kld_element = logvar_2 - logvar_1 + \\\n",
    "                      (logvar_1.exp() + (mean_1-mean_2).pow(2)) / (logvar_2.exp()+1e-8) - 1\n",
    "        \n",
    "        return 0.5 * torch.sum(kld_element, dim = 1)\n",
    "\n",
    "\n",
    "    def _nll_bernoulli(self, p, x):\n",
    "        \"\"\" \n",
    "        Reconstruction Loss: negative log likelihood of Bernoulli \n",
    "        random variable x, parameteried by p.\n",
    "        You might be used to seeing this formulas variables reversed,\n",
    "        note that if x = y and p = x,this is the same as Binary Cross Entropy.\n",
    "        # return F.binary_cross_entropy(p, x, size_average=False)\n",
    "        In the VAE example, p is the output of the decoder [0,1],\n",
    "        and x is the input {0,1}. \n",
    "        \"\"\"\n",
    "        return -torch.sum(x*torch.log(p+1e-8)+(1-x)*torch.log(1-p+1e-8),dim=1)\n",
    "        \n",
    "class ConvNetEncoder(nn.Module):\n",
    "    def __init__(self, psi_dim, h_dim, z_dim):\n",
    "        super(ConvNetEncoder, self).__init__()\n",
    "\n",
    "        self.psi_dim = psi_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "        self.conv1x1_1 = nn.Conv2d(1, 8, kernel_size=1, padding=2)\n",
    "        self.conv3x3_1 = nn.Conv2d(1, 8, kernel_size=3, padding=3)\n",
    "        self.conv5x5_1 = nn.Conv2d(1, 8, kernel_size=5, padding=4)\n",
    "        self.conv7x7_1 = nn.Conv2d(1, 8, kernel_size=7, padding=5)\n",
    "        self.conv_dim_halving_1 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv1x1_2 = nn.Conv2d(32, 8, kernel_size=1, padding=0)\n",
    "        self.conv3x3_2 = nn.Conv2d(32, 8, kernel_size=3, padding=1)\n",
    "        self.conv5x5_2 = nn.Conv2d(32, 8, kernel_size=5, padding=2)\n",
    "        self.conv7x7_2 = nn.Conv2d(32, 8, kernel_size=7, padding=3)\n",
    "        self.conv_dim_halving_2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 64)\n",
    "        self.fc2_mean = nn.Linear(32 + psi_dim, h_dim)\n",
    "        self.fc2_logvar = nn.Linear(32 + psi_dim, h_dim)\n",
    "        self.fc3_mean = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3_logvar = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "    def forward(self, psi, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.cat([\n",
    "            self.conv1x1_1(x),\n",
    "            self.conv3x3_1(x),\n",
    "            self.conv5x5_1(x),\n",
    "            self.conv7x7_1(x)\n",
    "        ], dim=1)\n",
    "        x = self.conv_dim_halving_1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = torch.cat([\n",
    "            self.conv1x1_2(x),\n",
    "            self.conv3x3_2(x),\n",
    "            self.conv5x5_2(x),\n",
    "            self.conv7x7_2(x)\n",
    "        ], dim=1)\n",
    "        x = self.conv_dim_halving_2(x)\n",
    "\n",
    "        x = x.view(-1, 8 * 8 * 64)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x_mean = F.relu(self.fc2_mean(torch.cat([psi, x[:,:32]], dim = 1)))\n",
    "        x_logvar = F.relu(self.fc2_logvar(torch.cat([psi, x[:,32:]], dim = 1)))\n",
    "\n",
    "        x_mean = self.fc3_mean(x_mean)\n",
    "        x_logvar = self.fc3_logvar(x_logvar)\n",
    "\n",
    "        return x_mean, x_logvar\n",
    "\n",
    "class ConvNetDecoder(nn.Module):\n",
    "    def __init__(self, psi_dim, h_dim, z_dim):\n",
    "        super(ConvNetDecoder, self).__init__()\n",
    "\n",
    "        self.psi_dim = psi_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(psi_dim + z_dim, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, 64 * 8 * 8)\n",
    "        self.deconv_dim_doubling_1 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.deconv1x1_1 = nn.ConvTranspose2d(8, 32, kernel_size=1, padding=0)\n",
    "        self.deconv3x3_1 = nn.ConvTranspose2d(8, 32, kernel_size=3, padding=1)\n",
    "        self.deconv5x5_1 = nn.ConvTranspose2d(8, 32, kernel_size=5, padding=2)\n",
    "        self.deconv7x7_1 = nn.ConvTranspose2d(8, 32, kernel_size=7, padding=3)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.deconv_dim_doubling_2 = nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.deconv1x1_2 = nn.ConvTranspose2d(8, 1, kernel_size=1, padding=0)\n",
    "        self.deconv3x3_2 = nn.ConvTranspose2d(8, 1, kernel_size=3, padding=1)\n",
    "        self.deconv5x5_2 = nn.ConvTranspose2d(8, 1, kernel_size=5, padding=2)\n",
    "        self.deconv7x7_2 = nn.ConvTranspose2d(8, 1, kernel_size=7, padding=3)\n",
    "\n",
    "\n",
    "    def forward(self, psi_cat_z):\n",
    "\n",
    "        x = F.relu(self.fc1(psi_cat_z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(-1, 64, 8, 8)\n",
    "        x = self.deconv_dim_doubling_1(x, output_size=(16,16))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.deconv1x1_1(x[:,0:8,:,:]) + self.deconv3x3_1(x[:,8:16,:,:]) + self.deconv5x5_1(x[:,16:24,:,:]) + self.deconv7x7_1(x[:,24:32,:,:])\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.deconv_dim_doubling_2(x, output_size=(32,32))\n",
    "        x = self.deconv1x1_2(x[:,0:8,:,:]) + self.deconv3x3_2(x[:,8:16,:,:]) + self.deconv5x5_2(x[:,16:24,:,:]) + self.deconv7x7_2(x[:,24:32,:,:])\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        x = x[:,0,2:30,2:30] #remove padding\n",
    "        x = x.contiguous().view(-1,28*28) #unwrap the image\n",
    "\n",
    "        return x\n",
    "    \n",
    "class VariationalConvDeconv(VariationalModelBase):\n",
    "    def init_nn_layers(self):\n",
    "\n",
    "        x_dim = self.x_dim\n",
    "        h_dim = self.h_dim\n",
    "        z_dim = self.z_dim\n",
    "        psi_dim = self.psi_dim\n",
    "\n",
    "        # generator\n",
    "        self.gen = ConvNetDecoder(psi_dim, h_dim, z_dim)\n",
    "\n",
    "        # inference\n",
    "        self.inf = ConvNetEncoder(psi_dim, h_dim, z_dim)\n",
    "\n",
    "        # prior\n",
    "        self.prior = nn.Sequential(\n",
    "            nn.Linear(psi_dim, h_dim),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.prior_mean = nn.Sequential(\n",
    "            nn.Linear(h_dim, z_dim)\n",
    "        )\n",
    "        self.prior_logvar = nn.Sequential(\n",
    "            nn.Linear(h_dim, z_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, psi_t, x_t, batch_size):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            psi_t - context, read vector from memory (batch_size, memory_m)\n",
    "            x_t - input vector (batch_size, input dimensions)\n",
    "        output:\n",
    "            z_sample - latentstate (batch_size, memory_m)\n",
    "            _x_t_mean - output vector (batch_size, input dimensions)\n",
    "            elbo_t - evidence lower bound (batch_size,)\n",
    "        \"\"\"\n",
    "        # Posterior Q(Z_t|X_t,Z_<t) = N(zt|z_mean(psi<t,xt), z_logvar(psi<t,xt)) \n",
    "        # aka z given context and x_t\n",
    "        z_mean, z_logvar = self.inf(psi_t, x_t)\n",
    "\n",
    "        # Prior P(Z_t|X<t,Z<t) = N(zt|z_mean(psi<t), z_logvar(psi<t)) \n",
    "        # aka prior over z_t given context\n",
    "        z_enc_prior = self.prior(psi_t)\n",
    "        z_mean_prior = self.prior_mean(z_enc_prior)\n",
    "        z_logvar_prior = self.prior_logvar(z_enc_prior)\n",
    "\n",
    "        # get a sample of z_t\n",
    "        z_sample = self.sample_gaussian(z_mean, (0.5 * z_logvar).exp())\n",
    "\n",
    "        # get distribution over x_t given z_t and the context\n",
    "        x_mean = self.gen(torch.cat([psi_t, z_sample], dim=1))\n",
    "\n",
    "        # compute kld between the posterior and prior \n",
    "        kld = self._kld_gauss(z_mean, z_logvar, z_mean_prior, z_logvar_prior)\n",
    "        # log-likelihood of x_t and x_mean (sub-elbo) \n",
    "        nll = self._nll_bernoulli(x_mean, x_t)  \n",
    "        elbo_t = - nll - kld # Reconsruction loss and KL divergence \n",
    "\n",
    "        return z_sample, x_mean, elbo_t\n",
    "\n",
    "    def sample_x_mean(self, psi):\n",
    "        \"\"\" used in the generate method of the combined model \"\"\"\n",
    "        # compute prior over z_t given context\n",
    "        z_enc_prior = self.prior(psi)\n",
    "        z_mean_prior = self.prior_mean(z_enc_prior)\n",
    "        z_logvar_prior = self.prior_logvar(z_enc_prior)\n",
    "        z_sample = self.sample_gaussian(z_mean_prior,(0.5*z_logvar_prior).exp())\n",
    "        x_mean = self.gen(torch.cat([psi, z_sample], dim=1))\n",
    "        return z_sample, x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadState(nn.Module):\n",
    "    def __init__(self, memory):\n",
    "        super(ReadState, self).__init__()\n",
    "        self.memory = memory\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "    def reset(self, batch_size):\n",
    "        self.w = torch.zeros(batch_size, self.memory.N, device = self.device)\n",
    "        self.w[:,0] = 1.0 # set reader attention at first spot in the memory\n",
    "        self.r = self.memory.read(self.w)\n",
    "\n",
    "class ControllerState(nn.Module):\n",
    "    def __init__(self, controller):\n",
    "        super(ControllerState, self).__init__()\n",
    "        self.controller = controller\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        # starting hidden state is a learned parameter\n",
    "        self.lstm_h = Parameter(torch.randn(self.controller.num_layers, \n",
    "                                                 1, self.controller.hidden_size) * 0.05)\n",
    "        \n",
    "        self.lstm_c = Parameter(torch.randn(self.controller.num_layers, \n",
    "                                                 1, self.controller.hidden_size) * 0.05)\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def reset(self, batch_size):\n",
    "        h = self.lstm_h.clone().repeat(1, batch_size, 1)\n",
    "        c = self.lstm_c.clone().repeat(1, batch_size, 1)\n",
    "        self.state = h, c\n",
    "\n",
    "class LatentState(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(LatentState, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "    def reset(self, batch_size):\n",
    "        self.state = torch.zeros(batch_size, self.latent_size, device = self.device)\n",
    "\n",
    "class State(nn.Module):\n",
    "    def __init__(self, memory, controller):\n",
    "        super(State, self).__init__()\n",
    "        self.memory = memory\n",
    "        self.controller = controller\n",
    "\n",
    "    def reset(self, batch_size):\n",
    "        # setup readstate\n",
    "        self.readstate = ReadState(self.memory)\n",
    "        self.readstate.reset(batch_size)\n",
    "\n",
    "        # setup controller state\n",
    "        self.controlstate = ControllerState(self.controller)\n",
    "        self.controlstate.reset(batch_size)\n",
    "\n",
    "        # setup latent state\n",
    "        self.latentstate = LatentState(self.memory.M)\n",
    "        self.latentstate.reset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMController(nn.Module):\n",
    "    \"\"\"\n",
    "    A Neural Turing Machine controller based on LSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMController, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def reset_parameters(self, stdv=1e-1):\n",
    "        for weight in self.parameters():\n",
    "            weight.data.normal_(0, stdv)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "             x - latentstate (batch_size, memory_m),\n",
    "                 the current hidden state output from \n",
    "                 last layer of LSTM (seq_len=1, batch, directions*hidden_size)\n",
    "                 \n",
    "             prev_state - controlstate is a tuple,\n",
    "                          previous hidden and cell state (h, c)\n",
    "                          (num_layers*num_directions, batch, memory_m)\n",
    "        output:\n",
    "            outp -  the hidden state from the last layer of the LSTM, \n",
    "                    for each t, in seq_len, here seq_len = 1, so it is \n",
    "                    squeezed out with .squeeze(0)\n",
    "                    (seq_len, batch_size, num_directions*memory_m)\n",
    "            state - tuple containing the hidden and cell state at \n",
    "                    the last time step t in seq_len. both\n",
    "                    (num_layers*num_directions, batch, memory_m)\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(0) \n",
    "        outp, state = self.lstm(x, prev_state)\n",
    "        return outp.squeeze(0), state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Turing Machine\n",
    "\n",
    "The main NTM class. We will explore the mechanics of addressing, reading and writing in the cells below the NTM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTM(nn.Module):\n",
    "    \"\"\" Neural Turing Machine Memory\"\"\"\n",
    "    def __init__(self, N, M, controller_size):\n",
    "        \n",
    "        \"\"\"Initialize the Memory matrix.\n",
    "        The memory's dimensions are (batch_size x N x M).\n",
    "        Each batch has it's own memory matrix.\n",
    "        N: Number of rows in the memory.\n",
    "        M: Number of columns/features in the memory.\n",
    "        \"\"\"\n",
    "        super(NTM, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        self.controller_size = controller_size\n",
    "\n",
    "        self.memory0 = torch.ones(self.N, self.M, \n",
    "                                  device = self.device).abs_()*1e-6\n",
    "\n",
    "        # create Fully Connected layer for addressing using controller output\n",
    "        self.address_params_sizes = [self.M, 1, 1, 3, 1]\n",
    "        self.addresses =  nn.Linear(self.controller_size, \n",
    "                                    sum(self.address_params_sizes))  # sums to 26\n",
    "        self.to(self.device)\n",
    "\n",
    "    def reset(self, batch_size):\n",
    "        \"\"\"Reset the memory\"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.write_loc = 0\n",
    "\n",
    "        self.memory = self.memory0.clone().repeat(batch_size, 1, 1)\n",
    "\n",
    "    def visualize(self, savefile):\n",
    "        torchvision.utils.save_image(self.memory, savefile)\n",
    "\n",
    "    def size(self):\n",
    "        return self.N, self.M\n",
    "\n",
    "    def read(self, w):\n",
    "        \"\"\"Read from memory (according to section 3.1)\"\"\"\n",
    "        return torch.matmul(w.unsqueeze(1), self.memory).squeeze(1)\n",
    "\n",
    "    def write(self, a):\n",
    "        if a is None:\n",
    "            return\n",
    "        \n",
    "        w = torch.zeros(self.batch_size, self.N)\n",
    "        w[:, self.write_loc] = 1.0\n",
    "        e = torch.ones(self.batch_size, self.M)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.memory = self.memory.cuda()\n",
    "            w = w.cuda()\n",
    "            e = e.cuda()\n",
    "            a = a.cuda()\n",
    "\n",
    "        erase = torch.matmul(w.unsqueeze(-1), e.unsqueeze(1))\n",
    "        add = torch.matmul(w.unsqueeze(-1), a.unsqueeze(1))\n",
    "\n",
    "        # write to memory\n",
    "        self.memory = self.memory * (1 - erase) + add\n",
    "        self.write_loc = (self.write_loc + 1) % self.N\n",
    "\n",
    "    def address(self, controller_output, w_prev):\n",
    "        \"\"\"NTM Addressing (according to section 3.3)\n",
    "           both w_prev and ware Softmax weightings over rows \n",
    "           of the memory matrix with shapes (batch_size, memory_n)\n",
    "        input:\n",
    "            controller_output- (batch_size, controller_size)\n",
    "            w_prev - The weighting produced in the previous time step\n",
    "        output:\n",
    "            w - new Softmax weighting over rows of the memory matrix\n",
    "        \"\"\"\n",
    "        address_params = self.addresses(controller_output)\n",
    "        \n",
    "        k, beta, g, s, gamma = self.split_cols(address_params, \n",
    "                                               self.address_params_sizes)\n",
    "        \"\"\"\n",
    "        k - The key vector (batch_size, memory_m) (a vector)\n",
    "        beta - The key strength (focus) (batch_size, 1) (0,infinity)\n",
    "        g - Scalar interpolation gate with w_prev (batch_size, 1) (0,1)\n",
    "        s - Shift weighting (batch_size, memory_n) (sums to 1)\n",
    "        gamma - Sharpen weighting scalar (batch_size, 1) (1,infinity)\n",
    "        \"\"\"\n",
    "        beta = F.softplus(beta)\n",
    "        g = torch.sigmoid(g)\n",
    "        s = F.softmax(s, dim=1)\n",
    "        gamma = 1 + F.softplus(gamma)\n",
    "        # Content Addressing\n",
    "        wc = self._similarity(k, beta)\n",
    "        # Location Adressing\n",
    "        wg = self._interpolate(w_prev, wc, g)\n",
    "        w_hat = self._shift(wg, s)\n",
    "        w = self._sharpen(w_hat, gamma)\n",
    "\n",
    "        return w\n",
    "\n",
    "    def split_cols(self, mat, lengths):\n",
    "        \"\"\"Split a 2D matrix to variable length columns.\"\"\"\n",
    "        assert mat.size()[1] == sum(lengths), \"Lengths must be summed to num columns\"\n",
    "        l = np.cumsum([0] + lengths) # [ 0, 20, 21, 22, 25, 26]\n",
    "        results = []\n",
    "        for s, e in zip(l[:-1], l[1:]):  # 0 20, 20 21, ... \n",
    "            results += [mat[:, s:e]]\n",
    "        return results\n",
    "    \n",
    "    def _similarity(self, k, beta):\n",
    "        k = k.view(self.batch_size, 1, -1)\n",
    "        w = F.softmax(beta * F.cosine_similarity(self.memory + 1e-16, \n",
    "                                                 k + 1e-16, dim=-1), dim=1)\n",
    "        return w\n",
    "\n",
    "    def _interpolate(self, w_prev, wc, g):\n",
    "        return g * wc + (1 - g) * w_prev\n",
    "\n",
    "    def convolve(self, w, s):\n",
    "        \"\"\"Circular convolution implementation.\"\"\"\n",
    "        assert s.size(0) == 3\n",
    "        t = torch.cat([w[-1:], w, w[:1]])\n",
    "        c = F.conv1d(t.view(1, 1, -1), s.view(1, 1, -1)).view(-1) \n",
    "        # .view(-1) gets rid of the first two 1 dims inc\n",
    "        return c\n",
    "    \n",
    "    def _shift(self, wg, s):\n",
    "        result = torch.zeros(wg.size(), device = self.device)\n",
    "        for b in range(self.batch_size):\n",
    "            result[b] = self.convolve(wg[b], s[b])\n",
    "        return result\n",
    "\n",
    "    def _sharpen(self, w_hat, gamma):\n",
    "        w = w_hat ** gamma\n",
    "        w = torch.div(w, torch.sum(w, dim=1).view(-1, 1) + 1e-16)\n",
    "        return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory matrix\n",
      " torch.Size([1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# lets suppose that the rows of memory = 4, the columns of memory = 5, rnn hidden = 6 and batch_size = 1\n",
    "memory_n = 4\n",
    "memory_m = 5\n",
    "controller_size = 6\n",
    "batch_size = 1\n",
    "ntm = NTM(memory_n, memory_m, controller_size)\n",
    "ntm.reset(batch_size)\n",
    "print(\"memory matrix\\n\", ntm.memory.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Controller \n",
    "\n",
    "At each timestep the controller takes in information about the environment in the form of the latent state, along with information about the it's past actions and environments in the form on the controller state and generates a vector `cout` used to address reading from the memory, ie query.  cout -> (k, beta, g, s, gamma) -> w  \n",
    "\n",
    "The LSTM has 3 inputs and 3 outputs: \n",
    "input, hidden_state, cell_state = latent state, controller hidden, controller cell\n",
    "output, hidden_state, cell_state = controller output vector (cout), controller hidden, controller cell\n",
    "\n",
    "`self.state.readstate.w = self.memory.address(cout, self.state.readstate.w)`\n",
    "        \n",
    "`self.state.readstate.r = self.memory.read(self.state.readstate.w)`\n",
    "\n",
    "Notice the use of the softplus function. The softplus function is quite similar to the Rectified Liner Unit with outputs in the range (0, ∞), with the main difference being softplus differentiability at the x = 0\n",
    "\n",
    "<img src=\"saved/images/activationfunction.png\" width=400 height=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent state torch.Size([1, 5])\n",
      "cout.shape, h.shape, c.shape (num_layers*num_directions=1, batch=1, hidden_size=1)\n",
      "torch.Size([1, 6]) torch.Size([1, 1, 6]) torch.Size([1, 1, 6])\n",
      "w.shape torch.Size([1, 4])\n",
      "tensor([[ 0.0662, -0.1405,  0.1248,  0.2219, -0.1425]], device='cuda:0')\n",
      "tensor([[0.0218]], device='cuda:0') tensor([[0.0404]], device='cuda:0')\n",
      "tensor([[0.7041]], device='cuda:0') tensor([[0.5101]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "num_layers = 1\n",
    "lstm = LSTMController(input_size = memory_m, hidden_size = controller_size, num_layers = num_layers)\n",
    "state = State(ntm, lstm)\n",
    "state.reset(batch_size)\n",
    "print(\"latent state\", state.latentstate.state.shape) # this is the top lstm layer hidden state (batch_size, memory_m)\n",
    "cout, state.controlstate.state = lstm(state.latentstate.state, state.controlstate.state)\n",
    "h, c = state.controlstate.state\n",
    "print(\"cout.shape, h.shape, c.shape (num_layers*num_directions=1, batch=1, hidden_size=1)\")\n",
    "print(cout.shape, h.shape, c.shape) \n",
    "state.readstate.w = ntm.address(cout, state.readstate.w)\n",
    "print(\"w.shape\", state.readstate.w.shape)\n",
    "address_params = ntm.addresses(cout)\n",
    "k, beta, g, s, gamma = ntm.split_cols(address_params, ntm.address_params_sizes)\n",
    "print(k.data)\n",
    "print(beta.data, g.data)\n",
    "beta = F.softplus(beta)\n",
    "g = torch.sigmoid(g)\n",
    "print(beta.data, g.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Neural Turing Machine paper](https://arxiv.org/pdf/1410.5401.pdf) explains the components of neural memory. [This blog](https://rylanschaeffer.github.io/content/research/neural_turing_machine/main.html) does a great job expalaining the paper to technical non-researchers. \n",
    "\n",
    "## Addressing\n",
    "Adressing is creating weight vectors across the rows of the memory to determine where to read and write. Each stage generates an intermediate weight vector that gets passed to the next stage. First is content addressing:\n",
    "\n",
    "### Content Adressing \n",
    "generates a weight vector based on how similar each row in memory is to a length-C vector key k_t emitted by the controller\n",
    "\n",
    "<img src=\"https://rylanschaeffer.github.io/content/research/neural_turing_machine/ntm_addr_1.png\">\n",
    "\n",
    "For each head, the controller produces a key vector kt that is compared to each row of Mt using a similarity measure. In this paper, the authors use cosine similarity\n",
    "\n",
    "$$ K(k_t, M_t(i)) = \\frac{k_t \\cdot M_t(i)}{\\|k_t\\| \\cdot \\|M_t(i)\\|}$$ \n",
    "\n",
    "The PyTorch version of this formula is \n",
    "\n",
    "`F.cosine_similarity(self.memory + 1e-16, k + 1e-16, dim=-1)`\n",
    "\n",
    "The variable `wc` in ` wc = self._similarity(k, beta)` is the weighted softmax of these similarities and can be used as and an attention weighting over the rows of the matrix based on similarity to a generated vector k. Larger betas cause the distribution over the rows of the memory to be more concentrated on the highest cosine similarity row, thus beta is called the key strength or focus.\n",
    "\n",
    "$$w_t^c(i) = \\frac{exp\\Big(\\beta_t K (k_t, M_t(i))\\Big)}{\\sum_j exp\\Big(\\beta_t K(k_t, M_t(j))\\Big)}$$\n",
    "\n",
    "`wc = F.softmax(beta * F.cosine_similarity(self.memory + 1e-16, k + 1e-16, dim=-1), dim=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 5]) torch.Size([1, 5])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(ntm.memory.shape, k.shape)\n",
    "cos_sim = F.cosine_similarity(ntm.memory + 1e-16, k + 1e-16, dim=-1)\n",
    "print(cos_sim.shape)\n",
    "wc = F.softmax(beta * cos_sim, dim=1)\n",
    "print(wc.shape, beta.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## location-based addressing\n",
    "\n",
    "In some cases, we may want to read from specific memory locations instead of looking for specific memory values. The example the authors give is the function f(x,y)=x∗y. In this case, we don't care what the values of x and y are, just that x and y are consistently read from the same memory locations. This is called location-based addressing, and to implement it, we'll need three more stages. In the second stage, a scalar parameter g ∈ (0,1), called the interpolation gate, blends the content weight vector wc with the previous time step's weight vector w_t−1 to produce the gated weighting wg. This allows the system learn when to use (or ignore) content-based addressing.\n",
    "\n",
    "<img src=\"https://rylanschaeffer.github.io/content/research/neural_turing_machine/ntm_addr_2.png\">\n",
    "\n",
    "$$w_t^g \\leftarrow g_t w_t^c + (1- g_t) w_{t-1}$$\n",
    "\n",
    "                                              wg = g * wc + (1 - g) * w_prev\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_prev tensor([[0.2686, 0.2873, 0.2011, 0.2431]], device='cuda:0')\n",
      "g tensor([[0.5101]], device='cuda:0')\n",
      "wg tensor([[0.2591, 0.2683, 0.2260, 0.2466]], device='cuda:0') torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# for demonstration purposes we use a random w_prev\n",
    "w_prev = F.softmax(torch.rand((batch_size, memory_n)), dim = -1)\n",
    "if torch.cuda.is_available():\n",
    "    w_prev = w_prev.cuda()\n",
    "print(\"w_prev\", w_prev.data)\n",
    "print(\"g\", g.data)\n",
    "wg = g * wc + (1 - g) * w_prev\n",
    "print(\"wg\", wg.data, wg.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shift\n",
    "\n",
    "s - Shift weighting (batch_size, memory_n) (sums to 1)\n",
    "\n",
    "We'd like the controller to be able to shift focus to other rows. Let's suppose that as one of the system's parameters, the range of allowable shifts is specified. For example, a head's attention could shift forward a row (+1), stay still (0), or shift backward a row(-1). \n",
    "\n",
    "<img src=\"https://rylanschaeffer.github.io/content/research/neural_turing_machine/ntm_addr_3.png\">\n",
    "\n",
    "We'll perform the shifts modulo R so that a shift forward at the bottom row of memory moves the head's attention to the top row, and similarly for a shift backward at the top row. After interpolation, each head emits a normalized shift weighting st, and the following convolutional shift is performed to produce the shifted weight w_hat\n",
    "\n",
    "$$\\tilde{w}_t(i) \\leftarrow \\sum\\limits_{j=0}^{R-1} w_t^g(j) s_t(i-j)$$\n",
    "\n",
    "                           F.conv1d(t.view(1, 1, -1), s.view(1, 1, -1)).view(-1)\n",
    "\n",
    "I never liked this notation for convolution. it leaves alot unsaid. think of s as being sliding window dot product, if you have already done the intro to pytorch lesson with 2D image convolutions, you might think of s as a filter of size 3 being applied to the image wg. To create the wrap-around padding effect, the last element is appended to the beginning and the first element is appended to the end. since the filter size is 3, this is just the right padding to result in an output tensor of the same size as the input. \n",
    "\n",
    "The F.conv1D function takes an input of shape (batch_size, input channels, sequence length), filter of shape (output channels, input channels, filter length) and outputs a tensor of shape (batch_size, output channels, output sequence length) \n",
    "\n",
    "If you are wondering why we have a for loop that goes through each sample in the batch, it is because we are not sharing weights across samples, each sample's filter is indenpendant and is part of its own independant history of states and actions, this is not a 1:1 mapping task where we are doing the same task for every sample in the batch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s tensor([[ 0.3183, -0.3265, -0.2234]], device='cuda:0')\n",
      "shift tensor([0.4747, 0.2491, 0.2762], device='cuda:0') torch.Size([3])\n",
      "wg tensor([0.2591, 0.2683, 0.2260, 0.2466], device='cuda:0') torch.Size([4])\n",
      "t tensor([[[0.2466, 0.2591, 0.2683, 0.2260, 0.2466, 0.2591]]], device='cuda:0') torch.Size([1, 1, 6])\n",
      "c tensor([0.2557, 0.2522, 0.2518, 0.2403], device='cuda:0') torch.Size([4])\n",
      "tensor([[0.2557]], device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([[0.2403]], device='cuda:0', grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "# a quick reminder that s is a probability density and so is wg\n",
    "print(\"s\",s.data)\n",
    "s = F.softmax(s, dim=1)\n",
    "# to demonstrate, here is the convolution operation performed on a single sample \n",
    "shift = s[0]\n",
    "w_gate = wg[0]\n",
    "print(\"shift\", shift.data, shift.shape)\n",
    "print(\"wg\", w_gate.data, w_gate.shape)\n",
    "t = torch.cat([w_gate[-1:], w_gate, w_gate[:1]])\n",
    "print(\"t\",t.view(1, 1, -1).data, t.view(1, 1, -1).shape)\n",
    "c = F.conv1d(t.view(1, 1, -1), shift.view(1, 1, -1)).view(-1) # .view(-1) gets rid of the first two 1 dims \n",
    "print(\"c\", c.data, c.shape)\n",
    "# the first and last window of a sliding window dot product between s and wg, ie convolution\n",
    "print(torch.einsum('ijk,ijk->ij', [t.view(1, 1, -1)[:,:,:3], s.view(1, 1, -1)]))\n",
    "print(torch.einsum('ijk,ijk->ij', [t.view(1, 1, -1)[:,:,-3:], s.view(1, 1, -1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat tensor([[0.2557, 0.2522, 0.2518, 0.2403]], device='cuda:0') torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# now lets apply the convolutional shift to the entire batch\n",
    "w_hat = ntm._shift(wg, s) \n",
    "print(\"w_hat\", w_hat.data, w_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth and final stage, sharpening, is used to prevent the shifted weight w_hat from blurring. To do this, a scalar gamma >= 1 is required\n",
    "\n",
    "$$w_t(i) \\leftarrow \\frac{\\tilde{w}_t(i)^{\\gamma_t}}{\\sum\\limits_j \\tilde{w}_t(j)^{\\gamma_t}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w tensor([[0.2603, 0.2540, 0.2531, 0.2326]], device='cuda:0') torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "gamma = 1 + F.softplus(gamma) # gamma should be in range 1 to infinity \n",
    "w = w_hat ** gamma\n",
    "w = torch.div(w, torch.sum(w, dim=1).view(-1, 1) + 1e-16)\n",
    "print(\"w\", w.data, w.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing \n",
    "\n",
    "$$\\mathcal{M}_t^{erased}(i) \\leftarrow \\mathcal{M}_{t-1}(i)[\\mathbf{1} - w_t(i) e_t ]$$\n",
    "\n",
    "$$\\mathcal{M}_t(i) \\leftarrow \\mathcal{M}_t^{erased}(i) + w_t(i) a_t$$\n",
    "\n",
    "$$\\mathcal{M}_t(i) \\leftarrow \\mathcal{M}_{t-1}(i)[\\mathbf{1} - w_t(i) e_t ] + w_t(i) a_t $$\n",
    "\n",
    "The initial write function sequentially overwrites rows in the memory whereas the another possibility \n",
    "might be to intelligently choose which row to overwrite by learning a write weighting ww and erase vector e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06],\n",
      "         [1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06],\n",
      "         [1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06],\n",
      "         [1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06, 1.0000e-06]]],\n",
      "       device='cuda:0')\n",
      "tensor([[-1.4638,  0.2284, -1.4672, -0.9524,  0.8018]])\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      "tensor([[[-1.4638,  0.2284, -1.4672, -0.9524,  0.8018],\n",
      "         [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000, -0.0000,  0.0000]]], device='cuda:0')\n",
      "tensor([[[-1.4638e+00,  2.2841e-01, -1.4672e+00, -9.5241e-01,  8.0181e-01],\n",
      "         [ 1.0000e-06,  1.0000e-06,  1.0000e-06,  1.0000e-06,  1.0000e-06],\n",
      "         [ 1.0000e-06,  1.0000e-06,  1.0000e-06,  1.0000e-06,  1.0000e-06],\n",
      "         [ 1.0000e-06,  1.0000e-06,  1.0000e-06,  1.0000e-06,  1.0000e-06]]],\n",
      "       device='cuda:0')\n",
      "ntm.write_loc 1\n"
     ]
    }
   ],
   "source": [
    "print(ntm.memory.data)\n",
    "a = torch.randn(batch_size, memory_m)\n",
    "print(a.data)\n",
    "w = torch.zeros(batch_size, memory_n)\n",
    "w[:, ntm.write_loc] = 1.0\n",
    "e = torch.ones(batch_size, memory_m)\n",
    "if torch.cuda.is_available():\n",
    "    a = a.cuda()\n",
    "    w = w.cuda()\n",
    "    e = e.cuda()\n",
    "erase = torch.matmul(w.unsqueeze(-1), e.unsqueeze(1))\n",
    "add = torch.matmul(w.unsqueeze(-1), a.unsqueeze(1))\n",
    "print(erase.data)\n",
    "print(add.data)\n",
    "ntm.memory = ntm.memory * (1 - erase) + add\n",
    "print(ntm.memory.data)\n",
    "ntm.write_loc = (ntm.write_loc + 1) % ntm.N\n",
    "print('ntm.write_loc', ntm.write_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelCell \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCell(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(ModelCell, self).__init__()\n",
    "\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:0\")\n",
    "\n",
    "        # set params\n",
    "        self.params = params\n",
    "\n",
    "        # create memory\n",
    "        self.memory = NTM(params.memory_n, params.memory_m, \n",
    "                          params.controller_size)\n",
    "\n",
    "        # create controller\n",
    "        self.controller = LSTMController(self.memory.M,\n",
    "                                         params.controller_size,\n",
    "                                         params.controller_layers)\n",
    "\n",
    "        # create state\n",
    "        self.state = State(self.memory, self.controller)\n",
    "\n",
    "        # create variational model\n",
    "        self.vae = VariationalConvDeconv(params.sequence_width,\n",
    "                                         params.variational_hidden_size,\n",
    "                                         params.memory_m,\n",
    "                                         params.memory_m)\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def reset_parameters(self, stdv=1e-1):\n",
    "        for weight in self.parameters():\n",
    "            weight.data.normal_(0, stdv)\n",
    "\n",
    "    def forward(self, X, batch_size):\n",
    "        \"\"\"\n",
    "        the controller is an LSTM: \n",
    "        self.state.latentstate.state is x_t\n",
    "        self.state.controlstate.state is h_t-1 and c_t-1\n",
    "        \n",
    "        x_t is a function of h_t-1 thru the address params that read \n",
    "        readstate.r from memory and x_t-1 thru latentstate.state\n",
    "        generated from the VAE's use of X, latentstate.state\n",
    "        is both written to memory and used as the next x_t \n",
    "        \"\"\"\n",
    "        cout, self.state.controlstate.state = self.controller(self.state.latentstate.state,\n",
    "                                                              self.state.controlstate.state)\n",
    "        \n",
    "        self.state.readstate.w = self.memory.address(cout, self.state.readstate.w)\n",
    "        \n",
    "        self.state.readstate.r = self.memory.read(self.state.readstate.w)\n",
    "        \n",
    "        self.state.latentstate.state, X_mean, elbo = self.vae(self.state.readstate.r, X, batch_size)\n",
    "        \n",
    "        self.memory.write(self.state.latentstate.state)\n",
    "\n",
    "        return elbo, X_mean # ELBO (evidence lower bound aka variational lower bound)\n",
    "\n",
    "    def generate(self):\n",
    "        \n",
    "        cout, self.state.controlstate.state = self.controller(self.state.latentstate.state,\n",
    "                                                              self.state.controlstate.state)\n",
    "        \n",
    "        self.state.readstate.w = self.memory.address(cout, self.state.readstate.w)\n",
    "        \n",
    "        self.state.readstate.r = self.memory.read(self.state.readstate.w)\n",
    "        \n",
    "        self.state.latentstate.state, X_mean = self.vae.sample_x_mean(self.state.readstate.r)\n",
    "        \n",
    "        self.memory.write(self.state.latentstate.state)\n",
    "\n",
    "        return X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# init model cell\n",
    "modelcell = ModelCell(params)\n",
    "modelcell.memory.reset(params.batch_size)\n",
    "modelcell.state.reset(params.batch_size)\n",
    "modelcell.controller.reset_parameters()\n",
    "print(modelcell.state.latentstate.state.shape)\n",
    "optimizer = torch.optim.Adam(modelcell.parameters(), lr=params.adam_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass samples throgh the model to probe the information flow and shapes of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = params.generate_random_batch(device = params.device)\n",
    "\n",
    "elbo, X_mean = modelcell(X[0], params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(batch_num, report_interval, last_loss, mean_loss):\n",
    "    \"\"\"Prints the progress until the next report.\"\"\"\n",
    "    progress = (((batch_num - 1.0) % report_interval) + 1.0) / report_interval\n",
    "    fill = int(progress * 40)\n",
    "    clear_output(wait = True)\n",
    "    print(\"\\r\\tBATCH [{}{}]: {} (ELBO: {:.4f} Mean ELBO: {:.4f})\".format(\n",
    "        \"=\" * fill,\n",
    "        \" \" * (40 - fill),\n",
    "        batch_num,\n",
    "        last_loss,\n",
    "        mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\tBATCH [========================================]: 500 (ELBO: 335.1781 Mean ELBO: 379.9128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3f12001fd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"START TRAINING MODEL\"\"\"\n",
    "\n",
    "loss_history = []\n",
    "params.num_batches = 500\n",
    "for batch_num in range(params.num_batches):\n",
    "    # reset the states\n",
    "    modelcell.memory.reset(params.batch_size)\n",
    "    modelcell.state.reset(params.batch_size)\n",
    "\n",
    "    # init optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # generate data for the copy task\n",
    "    X, Y = params.generate_random_batch(device = params.device)\n",
    "\n",
    "    # input phase\n",
    "    for i in range(X.size(0)):\n",
    "        _elbo, _ = modelcell(X[i], params.batch_size) #the forward pass predicts elbo, X_mean\n",
    "\n",
    "    # output phase\n",
    "    elbo = 0\n",
    "    for i in range(Y.size(0)):\n",
    "        _elbo, _ = modelcell(Y[i], params.batch_size) #the forward pass predicts elbo, X_mean\n",
    "        elbo += _elbo\n",
    "\n",
    "    # mean ELBO for the entire batch\n",
    "    mean_neg_elbo = -elbo.mean()\n",
    "    mean_neg_elbo.backward()\n",
    "\n",
    "    # log elbo history\n",
    "    loss_history.append(mean_neg_elbo.data)\n",
    "\n",
    "    clip_grads(modelcell, params.clip_grad_thresh)\n",
    "    optimizer.step()\n",
    "\n",
    "    if (batch_num + 1) % params.save_every == 0:\n",
    "        \n",
    "        mean_loss = sum(loss_history[-params.save_every:]) / params.save_every\n",
    "        progress_bar(batch_num + 1, \n",
    "                    params.num_batches, \n",
    "                    last_loss=mean_neg_elbo,\n",
    "                    mean_loss=mean_loss\n",
    "                    )\n",
    "        \n",
    "################### TEST #######################\n",
    "X, Y = params.generate_illustrative_random_batch(device=params.device)\n",
    "\n",
    "modelcell.memory.reset(batch_size=1)\n",
    "modelcell.state.reset(batch_size=1)\n",
    "\n",
    "attention_history = torch.zeros(1 + X.size(0) + Y.size(0), \n",
    "                                modelcell.memory.N, device=params.device)\n",
    "attention_history[0] = modelcell.state.readstate.w.squeeze()\n",
    "\n",
    "# input phase\n",
    "for i in range(X.size(0)):\n",
    "    _elbo, _ = modelcell(X[i], params.batch_size)\n",
    "    attention_history[1 + i] = modelcell.state.readstate.w.squeeze()\n",
    "\n",
    "# output phase\n",
    "Y_out = torch.zeros(Y.size(), device=params.device)\n",
    "for i in range(Y.size(0)):\n",
    "    Y_out[i] = modelcell.generate()\n",
    "    attention_history[1 + X.size(0) + i] = modelcell.state.readstate.w.squeeze()\n",
    "\n",
    "Y_out_binary = Y_out.cpu().clone().data\n",
    "Y_out_binary.apply_(lambda x: 0 if x < 0.5 else 1)\n",
    "\n",
    "_X = torch.cat([X[i].view(28,28) for i in range(X.size(0))], \n",
    "               dim = 1).data.cpu().numpy()\n",
    "\n",
    "_Y = torch.cat([Y[i].view(28,28) for i in range(Y.size(0))], \n",
    "                dim = 1).data.cpu().numpy()\n",
    "\n",
    "_Y_out = torch.cat([Y_out[i].view(28,28) for i in range(Y_out.size(0))], \n",
    "                   dim = 1).data.cpu().numpy()\n",
    "\n",
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(_X, cmap='Greys_r')\n",
    "axarr[0,1].imshow(_Y, cmap='Greys_r')\n",
    "axarr[1,0].imshow(_Y_out, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
